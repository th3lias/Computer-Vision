{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6X3li02SM9Q"
   },
   "source": [
    "|First Name     |Last Name    |MtkNr.      |Due Date  |\n",
    "|:-------------:|:-----------:|:----------:|:--------:|\n",
    "| Jakob    | Eggl  |12102678     | 11.11.2024, 16:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyimVoOqSM9U"
   },
   "source": [
    "<h1 style=\"color:rgb(150,100,10)\">Computer Vision Course</h1>\n",
    "<h2 style=\"color:rgb(150,100,10)\">Assignment 1 â€“ Image Processing Basics </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzN6VeYISM9V"
   },
   "source": [
    "<b>Authors:</b> O. Bimber, M. Abbass<br>\n",
    "<b>Date:</b> 10-08-2024\n",
    "\n",
    "<b>This file is part of the \"Computer Vision Course 2024W\" UE material.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzEgnGrsSM9V"
   },
   "source": [
    "<h2 style=\"color:rgb(150,100,10)\">Table of Contents</h2>\n",
    "<ol>\n",
    "    <a style=\"color:rgb(150,100,10)\" href=\"#Low-pass-filtering\"><li style=\"font-size:large;font-weight:bold\">Low-pass filtering</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-low-pass-filtering-in-the-spatial-domain\"><li style=\"font-size:medium\">Apply low-pass filtering in the spatial domain</li></a>\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-low-pass-filtering-in-the-frequency-domain\"><li style=\"font-size:medium\">Apply low-pass filtering in the frequency domain</li></a>\n",
    "    </ol>\n",
    "    <a style=\"color:rgb(150,100,10)\" href=\"#High-pass-filtering\"><li style=\"font-size:large;font-weight:bold\">High-pass filtering</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-high-pass-filter-using-Laplacian\"><li style=\"font-size:medium\">Apply a high-pass filter using the Laplacian operator</li></a>\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-high-pass-filter-using-image-subtraction\"><li style=\"font-size:medium\">Apply a high-pass filter using image subtraction</li></a>\n",
    "    </ol>\n",
    "    <a style=\"color:rgb(150,100,10)\" href=\"#Deconvolution\"><li style=\"font-size:large;font-weight:bold\">Deconvolution</li></a>\n",
    "    <ol style=\"margin-bottom:15px\">\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-deconvolution-as-division-in-frequency-domain\"><li style=\"font-size:medium\">Apply deconvolution by performing division in the frequency domain</li></a>\n",
    "        <a style=\"color:rgb(150,100,10)\" href=\"#Apply-deconvolution-with-Richardson-Lucy\"><li style=\"font-size:medium\">Apply deconvolution using the Richardson-Lucy algorithm</li></a>\n",
    "    </ol>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqNda7PnSM9X"
   },
   "source": [
    "<h1 style=\"color:rgb(255,0,0)\">Important Note</h1>\n",
    "<b>In this assignment, you can use the default parameters in any built-in function unless specified otherwise</b>.\n",
    "\n",
    "<b>All cells must be evaluated, and any unevaluated cell may lead to a loss of points, regardless of the correctness of the code.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sp5_4Vh7SM9Y",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convolve\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m restoration\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease create the resources folder and include all required files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "# Import all packages needed in this notebook.\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import convolve\n",
    "from skimage import restoration\n",
    "import os\n",
    "\n",
    "if not os.path.exists('resources'): raise TypeError(\"Please create the resources folder and include all required files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrTCFsz5SM9a"
   },
   "source": [
    "<a name=\"Low-pass-filtering\"></a><h2> Low-pass filtering</h2>\n",
    "In this asignment, we focus on one image, which is <i><b>zebras</b><i>, provided in the <i><b>resources</b><i> folder. We will now read the <i><b>zebras</b><i> image and then convert it to a grayscale image using the provided function <i><b>read_convert_Img</b><i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p31_yXjLSM9b"
   },
   "outputs": [],
   "source": [
    "def read_convert_Img(input_img):\n",
    "    if type(input_img) != str:\n",
    "        raise ValueError(\"input must be string)\")\n",
    "    img_Orig = cv.imread(input_img)\n",
    "    if img_Orig.ndim != 3:\n",
    "        raise ValueError(\"input image must have 3 channels)\")\n",
    "    img_Gray = np.mean(img_Orig, axis=2)\n",
    "    return img_Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGCRhE_BSM9c",
    "outputId": "a349728c-2055-46da-cc62-100dcd49801b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_Gray_Orig = read_convert_Img(\"resources/zebras.jpg\")/255.0\n",
    "\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IZ_ACmuSM9e"
   },
   "source": [
    "<a name=\"Apply-low-pass-filtering-in-the-spatial-domain\"></a><h3>Apply low-pass filtering in the spatial domain</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thrYz8ugSM9f"
   },
   "source": [
    "<b>Exercise 1.1. [8 Points]</b>\n",
    "\n",
    "<b>Goal:</b> After reading the input image, we will define a Gaussian low-pass filter. Our goal is to filter out the high-frequency components. Therefore, we will apply the convolution operation between the input image and the defined Gaussian low-pass filter in the <i><b>spatial domain</b></i>. To clearly observe the effect of the low-pass filter, we will apply the convolution operation <i><b>sequentially several times</b></i>.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Define the following Gaussian filter, as shown in the formula below, in a <i><b>NumPy</b><i> array.</li>\n",
    "<li>Apply this filter on the grayscale <i><b>zebras</b><i> image from above to compute the convolution operation. <b>Repeat this operation <i>5</i> times sequentially, using the output from each step as the input for the next convolution</b> while keeping the kernel the same</b>.</li>   \n",
    "<li>Display both images: the original image, and the final resulting image after running all the convolution steps.</li>\n",
    "</ul>\n",
    "<p>\n",
    "\n",
    "\\begin{equation}\n",
    "h_1 = \\left(\n",
    "\\begin{array}{rrr}\n",
    "    1/16 & 1/8 & 1/16 \\\\\n",
    "    1/8 & 1/4 & 1/8 \\\\\n",
    "    1/16 & 1/8 & 1/16\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "</p>\n",
    "        \n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Use the function <i><b>convolve</b><i> from <i><b>scipy.ndimage</b><i> library to compute the convolution operation.</li>\n",
    "<li>You can use the <i><b>constant</b><i> mode for the convolution.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ1tg_D3SM9g",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "h1 = 1/16 * np.array([[1, 2, 1],[2, 4, 2],[1, 2, 1]])\n",
    "\n",
    "# copy the original image\n",
    "img_gray_conv = img_Gray_Orig.copy()\n",
    "\n",
    "for i in range(5):\n",
    "    img_gray_conv = convolve(img_gray_conv, h1, mode='constant')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img_gray_conv, cmap='gray')\n",
    "plt.title('Blurred image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4Ln0mWuSM9g"
   },
   "source": [
    "<a name=\"Apply-low-pass-filtering-in-the-frequency-domain\"></a><h3>Apply low-pass filtering in the frequency domain</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jvMPebBSM9h"
   },
   "source": [
    "<b>Exercise 1.2. [5 Points]</b>\n",
    "\n",
    "<b>Goal:</b> After computing the filtered image in the spatial domain, let's compute the filtered image in the frequency domain.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Utilize the Fourier transform to convert the original input grayscale <i><b>zebras</b><i> image from the spatial domain to the frequency domain.</li>\n",
    "<li>Shift (centre) all frequency components around zero.</li>\n",
    "<li>Create a Gaussian filter in the frequency domain with a cutoff frequency of <b>40</b>.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Use the functions <i><b>fft2</b><i> and <i><b>fftshift</b><i> from the NumPy library to compute the frequency components and center all frequency components around zero, respectively.</li>\n",
    "<li>Use the function <i><b>create_Gaussian</b><i> to create the Gaussian filter in the frequency domain.</li>\n",
    "<li>The shape of the <i><b>created Gaussian filter</b><i> should be the same as the shape of the grayscale image <i>zebras<i>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9WkKaoNSM9h"
   },
   "outputs": [],
   "source": [
    "def create_Gaussian(h :int, w: int, cutoff : int ):\n",
    "    H = np.zeros((h,w), dtype=np.float32)\n",
    "    for u in range(h):\n",
    "        for v in range(w):\n",
    "            D = np.sqrt((u-h/2)**2 + (v-w/2)**2)\n",
    "            H[u,v] = np.exp(-D**2/(2*cutoff*cutoff))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQWCCXWlSM9i"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "unshifted_img_freq_domain = np.fft.fft2(img_Gray_Orig)\n",
    "\n",
    "shifted_img_freq_domain = np.fft.fftshift(unshifted_img_freq_domain)\n",
    "\n",
    "h, w = img_Gray_Orig.shape\n",
    "\n",
    "gaussian_filter_12 = create_Gaussian(h, w, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDyCqy3SM9j"
   },
   "source": [
    "<b>Exercise 1.3. [5 Points]</b>\n",
    "\n",
    "<b>Goal:</b > Our goal is to compute the filtered image by multiplying the spectrum of the input image with the spectrum of the Gaussian filter we created.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Compute the multiplication between the spectrum of <i><b>zebras</b><i> image and the spectrum of the Gaussian filter you created.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cCNr-osSM9j"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "img_freq_domain_filtered = np.multiply(shifted_img_freq_domain, gaussian_filter_12) # pointwise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwIbVM5OSM9j"
   },
   "source": [
    "<b>Exercise 1.4. [6 Points]</b>\n",
    "\n",
    "<b>Goal:</b> In this exercise, we aim to demonstrate the effect of low-pass filtering in the frequency domain by presenting all relevant results.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Display the spectrum of the <i>(zebras)<i> image <b>before centering the components at zero</b>.</li>\n",
    "<li>Display the spectrum of the <i>(zebras)<i> image <b>after centering the components at zero</b>.</li>\n",
    "<li>Display the spectrum of the created Gaussian filter.</li>\n",
    "<li>Display the result of the multiplication from <b>Exercise 1.3</b>.</li>\n",
    "<li><span style=\"color:red\">To draw the spectrum, you need to calculate the absolute value, followed by the <b>natural logarithm</b></span>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_mXxicQSM9k"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "# >>Here I used a ln(eps+|x|) in order to make the image more visible and start from 0<<\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "eps=0.01 # to avoid negative numbers\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(np.log(eps+np.abs(unshifted_img_freq_domain)), cmap='gray')\n",
    "plt.title('Original image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(np.log(eps+np.abs(shifted_img_freq_domain)), cmap='gray')\n",
    "plt.title('Shifted image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(gaussian_filter_12, cmap='gray')\n",
    "plt.title('Gaussian filter')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(np.log(eps+np.abs(img_freq_domain_filtered)), cmap='gray')\n",
    "plt.title('Filtered image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_pWOJF6SM9k"
   },
   "source": [
    "<b>Exercise 1.5. [5 Points]</b>\n",
    "\n",
    "<b>Goal:</b> We need to display the filtered image in the spatial domain. Therefore, let's convert the spectrum back to the spatial domain.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Compute the inverse Fourier transformation of <i><b>Exercise 1.3.</b><i> to transform the spectrum to the spatial domain.</li>\n",
    "<li>Display the resulting image.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Use the function <i><b>ifftshift</b><i> to move all values back to their original locations.</li>\n",
    "<li>Use the function <i><b>ifft2</b><i> to compute the spatial components from the spectrum.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcLE0wfwSM9l"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "spatial_image = np.abs(np.fft.ifft2(np.fft.ifftshift(img_freq_domain_filtered)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(spatial_image, cmap='gray')\n",
    "plt.title('Filtered image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1EGo1U7SM9l"
   },
   "source": [
    "<b>Exercise 1.6. [5 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Now, let's adjust the cutoff frequency by selecting a smaller value.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Repeat  <b>Exercises 1.2, 1.3, 1.4, and 1.5</b> with a cutoff frequency of <b>10</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFwDIP_qSM9m"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "\n",
    "cutoff_freq = 10\n",
    "\n",
    "\n",
    "\n",
    "unshifted_img_freq_domain = np.fft.fft2(img_Gray_Orig)\n",
    "\n",
    "shifted_img_freq_domain = np.fft.fftshift(unshifted_img_freq_domain)\n",
    "\n",
    "h, w = img_Gray_Orig.shape\n",
    "\n",
    "gaussian_filter_16 = create_Gaussian(h, w, cutoff_freq)\n",
    "\n",
    "img_freq_domain_filtered_new = np.multiply(shifted_img_freq_domain, gaussian_filter_16) # pointwise multiplication\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "eps = 0.01 # to avoid negative numbers\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(np.log(eps+np.abs(unshifted_img_freq_domain)), cmap='gray')\n",
    "plt.title('Original image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(np.log(eps+np.abs(shifted_img_freq_domain)), cmap='gray')\n",
    "plt.title('Shifted image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(gaussian_filter_16, cmap='gray')\n",
    "plt.title('Gaussian filter')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(np.log(eps+np.abs(img_freq_domain_filtered_new)), cmap='gray')\n",
    "plt.title('Filtered image spectrum')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "spatial_image_new = np.abs(np.fft.ifft2(np.fft.ifftshift(img_freq_domain_filtered_new)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(spatial_image_new, cmap='gray')\n",
    "plt.title('Filtered image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKb5MslzSM9m"
   },
   "source": [
    "<b>Exercise 1.7. [3 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Here, let's write our observation regarding the differences between cutoff frequency values.\n",
    "\n",
    "<b>Question</b>\n",
    "<ul>\n",
    "<li>Briefly, in 2 lines, explain the difference between the results at cutoff frequencies <b>10</b>, and <b>40</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzAikWiQSM9m"
   },
   "source": [
    "The explanation goes here:\n",
    "\n",
    "We can see, that for the smaller cutoff frequency value, we got a much more blurred image. This is because we don't allow high frequencies in that image (they get filtered out). High frequencies correspond to edges and corners which do not appear that much in the image where the cutoff was 10 instead of 40."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhRCOOAISM9n"
   },
   "source": [
    "<b>Exercise 1.8. [3 Points]</b>\n",
    "\n",
    "<b>Question</b>\n",
    "<ul>\n",
    "<li>What are the potential advantages of performing convolution in the frequency domain (i.e., multiplication) compared to convolution in the spatial domain (i.e., filtering)?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENOK4ALjSM9o"
   },
   "source": [
    "The explanation goes here:\n",
    "\n",
    "The first advantage is that we just can perform a standard multiplication instead of a convolution. Additionally we avoid the corner cases, where we need to think of padding etc. Another advantage is that we are more efficient, as we don't need that many calculations (especially for large filters) in the frequency domain, compared to the spatial domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNwK3rEuSM9o"
   },
   "source": [
    "<a name=\"High-pass-filtering\"></a><h2>High-pass filtering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYsRpVGdSM9o"
   },
   "source": [
    "<a name=\"Apply-high-pass-filter-using-Laplacian\"></a><h3>Apply a high-pass filter using the Laplacian operator</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-YOqxGySM9o"
   },
   "source": [
    "<b>Exercise 2.1. [10 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Instead of extracting low-frequency components with a low-pass filter, we will define a high-pass Laplacian filter and apply it using convolution in the spatial domain.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>\n",
    "\n",
    "Define the following $3 \\times 3$ Laplacian filter, as shown in the formula below, in a <i><b>NumPy</b><i> array.</li>\n",
    "\n",
    "<li>Apply this filter to the grayscale <i><b>zebras</b></i> image from above using convolution in the spatial domain.</li>\n",
    "<li>Display both images: the original image, and the resulting image after the convolution step.</li>\n",
    "</ul>\n",
    "<p>\n",
    "\n",
    "\\begin{equation}\n",
    "h_2 = \\left(\n",
    "    \\begin{array}{rrr}\n",
    "        0 & -1 & 0 \\\\\n",
    "        -1 & 4 & -1 \\\\\n",
    "        0 & -1 & 0\n",
    "    \\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "</p>\n",
    "\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Use the function <i><b>convolve</b><i> from the <i><b>scipy.ndimage</b><i> library to perform the convolution operation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuJKknrsSM9p",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "h2 = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])\n",
    "\n",
    "filtered_image_high_pass = convolve(img_Gray_Orig, h2, mode='constant')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(filtered_image_high_pass, cmap='gray')\n",
    "plt.title('Filtered image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7pFnTC3SM9p"
   },
   "source": [
    "<a name=\"Apply-high-pass-filter-using-image-subtraction\"></a><h3>Apply a high-pass filter using image subtraction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpqzlOcFSM9q"
   },
   "source": [
    "<b>Exercise 2.2. [10 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Let's extract the high-frequency components by subtracting the Gaussian-filtered image from the original input image.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Subtract the result of the Gaussian-filtered image in <b>Exercise 1.1</b> from the original input grayscale <i><b>zebras</b></i> image.</li>\n",
    "<li>Display the result of this subtraction.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>You can use the final result from <b>Exercise 1.1</b> after the five convolution iterations.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DM5JibMSM9q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "high_pass_using_difference = img_Gray_Orig - img_gray_conv\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(high_pass_using_difference, cmap='gray')\n",
    "plt.title('High pass using subtraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RIElRULSM9q"
   },
   "source": [
    "<b>Exercise 2.3. [7 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Let's add the high-frequency components back to the Gaussian-filtered image from <b>Exercise 2.2</b>.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Perform an additional operation between the result of <b>Exercise 2.2 (Subtracted image)</b> and the Gaussian-filtered image from <b>Exercise 1.1</b>.</li>\n",
    "<li>Display the result of this operation.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>You can use the final result from <b>Exercise 1.1</b> after five convolution iterations as well.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akWPVr_fSM9r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "new_image = high_pass_using_difference + img_gray_conv\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(new_image, cmap='gray')\n",
    "plt.title('High pass using subtraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnJ0JoF8SM9r"
   },
   "source": [
    "<b>Exercise 2.4. [3 Points]</b>\n",
    "\n",
    "<b>Question</b>\n",
    "<ul>\n",
    "<li>What do the results of <i><b>Exercise 2.1</b></i> and <i><b>Exercise 2.2</b></i> have in common in principle?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FowRbEQ6SM9r"
   },
   "source": [
    "The explanation goes here:\n",
    "\n",
    "Both images have filtered out the low frequencies. We do this is the first one be applying a filter directly, whereas in the second approach we subtract just the low frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylYczYlVSM9s"
   },
   "source": [
    "<a name=\"Deconvolution\"></a><h2> Deconvolution</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uRw_vRcSM9t"
   },
   "source": [
    "<a name=\"Apply-deconvolution-as-division-in-frequency-domain\"></a><h3>Apply deconvolution by performing division in the frequency domain</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-UDtUiMSM9t"
   },
   "source": [
    "<b>Exercise 3.1. [12 Points]</b>\n",
    "\n",
    "<b>Goal:</b> The goal here is to recover the original input <i><b>zebras</b><i> image by implementing deconvolution in the frequency domain using division instead of multiplication.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Use the result from <b>Exercise 1.5</b> by converting the image from the spatial domain to the frequency domain. Also, you need to shift the frequency components around the zero value.</li>\n",
    "<li>Then, divide this spectrum by the spectrum of the Gaussian filter created in <b>Exercise 1.2</b> with a cutoff frequency of <i><b>40</b><i>. </li>\n",
    "<li>After the division, compute the inverse Fourier transform of this result to convert from the frequency domain back to the spatial domain.</li>\n",
    "<li>Display the resulting image.</li>\n",
    "</ul>\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Before computing the inverse Fourier transform, Use the inverse Fourier shift function <i><b>ifftshift</b><i> from the <i><b>NumPy</b><i> library to move all components back to their original locations.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac1-4RbNSM9u"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "# converting to frequency domain\n",
    "freq_domain_ex1_5 = np.fft.fftshift(np.fft.fft2(spatial_image))\n",
    "# freq_domain_ex1_5 = img_freq_domain_filtered # TODO: Not sure if this is correct\n",
    "\n",
    "# add a small constant to avoid division by very small values\n",
    "resulting_image = np.divide(freq_domain_ex1_5, gaussian_filter_12)\n",
    "\n",
    "# back to spatial domain\n",
    "resulting_image = np.abs(np.fft.ifft2(np.fft.ifftshift(resulting_image)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_Gray_Orig, cmap='gray')\n",
    "plt.title('Original grayscale image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(resulting_image, cmap='gray')\n",
    "plt.title('Deconvoluted image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzL9RUXrSM9u"
   },
   "source": [
    "<b>Exercise 3.2. [3 Points]</b>\n",
    "\n",
    "<b>Question</b>\n",
    "<ul>\n",
    "<li>How can you explain the appearance of the artifacts?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2SXDrajSM9v"
   },
   "source": [
    "The explanation goes here:\n",
    "\n",
    "* Instability when dividing by small values of the kernel\n",
    "* Noise in the image can be increased by dividing with the kernel\n",
    "\n",
    "In practice, we usually solve the problem by solving the *2D-Poisson equation* $\\nabla^2 I = \\textrm{div}(G)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7bv83SMSM9v"
   },
   "source": [
    "<a name=\"Apply-deconvolution-with-Richardson-Lucy\"></a><h3>Apply deconvolution using the Richardson-Lucy algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huNBLA4_SM9w"
   },
   "source": [
    "<b>Exercise 3.3. [15 Points]</b>\n",
    "\n",
    "<b>Goal:</b> Let's apply deconvolution using an optimization method instead of division in the frequency domain. Please note that there are several optimization methods, but in this assignment, we will utilize the Richardson-Lucy optimization method.\n",
    "\n",
    "<b>Task</b>\n",
    "<ul>\n",
    "<li>Apply the Richardson-Lucy optimization method to perform the deconvolution step.</li>\n",
    "<li><b>Repeat this operation 5 times sequentially as well, using the output from each step as the input for the next input of the Richardson-Lucy optimization method while keeping the kernel the same</b>.</li>\n",
    "<li>Display only the corresponding final result after all runs.</li>\n",
    "</ul>\n",
    "<b>Hint</b>\n",
    "<ul>\n",
    "<li>Use the function <i><b>richardson_lucy</b><i> from the <i><b>skimage.restoration</b><i> library.</li>\n",
    "<li>Use the Gaussian kernel defined in <i><b>Exercise 1.1</b><i>.</li>\n",
    "<li>Use the output image from <i><b>Exercise 1.1</b></i> as the input image for the first time of the Richardson-Lucy optimization method.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Asgnsf2TSM9w"
   },
   "outputs": [],
   "source": [
    "# The code goes here\n",
    "\n",
    "richardson_lucy_deconv_img = img_gray_conv.copy()\n",
    "\n",
    "for i in range(5):\n",
    "    richardson_lucy_deconv_img = restoration.richardson_lucy(richardson_lucy_deconv_img, h1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_gray_conv, cmap='gray')\n",
    "plt.title('Convoluted image (5x Gaussian Kernel (h1))')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(richardson_lucy_deconv_img, cmap='gray')\n",
    "plt.title('Deconvoluted image (5x Richardson-Lucy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gRCNXynSM9x"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
